# Mission Specification: Automating science operational decisions

Each agent has a **mission** $M=\{O_1, \text{...} ,O_n\}$ defined a s a set of objectives. 
An **objective** is defined as a tuple $O=⟨w,p,R⟩$ where $w$ is the relative weight of that objective to the agent’s mission; $p$ is the primary geophysical parameter/data product (e.g., chlorophyll-Aconcentration); and $R=\{MR_1,...,MR_n\}$ is a set of measurement requirements. 
A (measurement) **requirement** is defined by a tuple $MR=⟨At,Th,Sc⟩$ where $At$ is an attribute of the data product (e.g., horizontal spatial resolution), and $Th$ and $Sc$ are used to define a preference function mapping values of the attribute $x$ to value $u(x)$. Specifically, $Th$ is an ordered list of threshold values $[x_1=x_{best},x_2,...,x_{worst}]$ and $Sc$ is an ordered list of scores $[u_1=u_{best},u_2,...,u_{worst}]$. For discrete attributes, $Th$ may contain all possible values and $Sc$ the score for each value. For continuous attributes, a continuous **preference function** $u(x)$ is interpolated from $Th$, $Sc$. For example, for spatial resolution, $Th=[10, 30, 100]$ and $Sc=[1.0, 0.75,0.25]$, one can fit a any smooth monotonically decreasing function, such as a sigmoid or generalized rational decay. 
<!-- (see Figure 10).

Figure 10: Example preference function for horizontal spatial resolution given Th=[10,30,100]and Sc=[1,0.75,0.25] -->

## Mission Requirements for Attribute Representation
### Spatial and temporal coverage and sampling
Spatiotemporal coverage and sampling are by far the most common attributes on which requirements will often be specified. 

**Spatial coverage** defines the region of interest for the observations, which can be specified as a list of *lat, lon* points or as a coverage grid defined over a region of interest. For regions larger than a point, spatial sampling can be specified with individual requirements for in horizontal and or vertical spatial resolution, as applicable. 

**Temporal coverage** defines the extent of time during which observations are to be performed. Forcontinuous monitoring objectives, this maybe a long time(e.g., a month), whereas for event-based objectives, it may bea much shorter duration depending on the event type (e.g., a few hours). During this time window, the temporal sampling with which observations are to be performed can be specified. For continuous monitoring objectives, one can simply define a revisit time requirement with the corresponding preference function. Note that the preference function specified for revisit time implicitly provides a way to value re-observations of the same point or region. The marginal value of the next observation is the slope of the preference function at the current revisit time. Alternatively, one can explicitly provide a preference function as a function of the number of observations of the same point. The latter can be more natural to define for event-based objectives.

### Other attributes
Many other attributes can be used to specify requirements. Some of the most common ones may be spectral coverage and sampling, radiometric resolution, or signal-to-noise ratio. Higher-level attributes can also be used, such as day-night or all-weather capability. Continuous or discrete preference functions can be defined for these and other attributes using the method described above, even for more qualitative attributes as demonstrated in the VASSAR papers (Selva et al., 2014; Selva & Crawley, 2013). 

## Geophysical Events of Interest
An event of interest can be detected by an agent. An **event** $E$ is defined by a tuple $E =⟨eventType, loc, t_{detect}, d_{exp}, S⟩$. It is initially characterized by a type, location $loc$, and detection time $t_{detect}$ . On board data processing is used to determine an expected duration $d_{exp}$ and severity $S$. 

## Tasks
### Default Mission Tasks
During nominal operations, satellites must schedule observations based on their default mission objectives. Any possible observation window is then represented as a default observation task $T_{default}=⟨param, loc, time⟩$ which indicate the the relevant parameter to be obeserved at location $loc$ and time or time interval $time$. These tasks are not shared between agents and are only considered by the agent generating them based on its own mission objectives. 

### Event-Driven Tasks
To respond to event $E$, one or more tasks $T_{event}=⟨param, loc, time, S, E, O_{ref}⟩$ are generated by the agent that discovered the event which require measuring the relevant parameters at location $loc$ and time or time interval $time$, and optionally a severity $S$. In addition, the agent can include the relevant event $E$ and objective $O_{ref}$ from its mission in the task request, to include the relevant requirements. One task is created for each geophysical parameter (or instrument type, by using level 1 data products such as TIR radiances). The requirements for cross-registered co-observations of the event (of different parameters, or from different sensor types) are managed by creating the corresponding task requests with the same location and time intervals. 

## Mission Objectives
### Default Mission Objectives

### Event-based Objectives
The mission specification described above is flexible enough to evaluate observations related to both regular objectives, related to the default mission of the agent, and event-based objectives, related to any task requests received to respond to events of interest. To see this, let us consider how the agent will value a specific task request during operations given its mission specification. 

## Evaluating Tasks using Mission Objectives
#### Mapping Objectives to Tasks
Given an observation task $j$, the agent must identify or create a relevant event-based objective. More specifically, assume the matrix $Rel_{jk}$ maps tasks to objectives. If all agents know a priori about all possible event types and has objectives defined for each of them, this is trivial and the corresponding objective can be used as is. If agents have different objectives and the agent receiving the task request does not have an objective related to that event, it must create a new objective. The weight of the new objective can be determined based on theweight of theclosest existing objectivein terms of semantic similarity, using ametric supported by a large language model that leverages the KG.The rest of the new event-based objective information can be copied from the task request, if it is provided. Otherwise, it can also be inferred using a similar approach. For example, it is reasonable to assume that to respond to events of interest about rivers, one may need similar spatial resolution. 

#### Valuing Event-based Objectives
Once an incoming task request is mapped to an existing or new objective, the valuation can proceed as explained above.  The task and the agent together determine the geometry of the observation, which can be used to compute the performance attributes $x_{ijl}$. The performance of the observation is the product of the utilities of all the performance attributes. Since some eventshave higher priority than others(captured by the severity ), the preference functions are objective-specific,and not all tasks are relevant to all objectives, the value of agent iperforming task j to the agent’s objective is computed as: 

$$P_{ijk} = S_j \cdot Rel_{jk} \prod_{MR_l \in R(O_k)}  u_{ikl}(x_{ijl})$$

From this, we can compute the total scientific value of agent $i$ performing task $j$ as the weighted sum of all objective values:

$$V_{ij} = \sum_{k} w_{ik} \cdot P_{ijk} $$

Finally, for the purposes of task planning and scheduling, we may want to consider the cost of performing a task in addition to its scientific value. Therefore, we define a utility function that in addition to consider the cost of performing the task, with some weight to define the relative importance of science vs cost. For satellite constellations, would typically represent the cost of the slewing maneuver needed to point at the location of the task. In that case, it is reasonable to use a very small (but non-zero)since energy can be regenerated “for free” with solar panels, but we still want to incentivize efficiency in the plan. 

$$U_{ij} = V_{ij} - \alpha E_{ij} $$

## Definitions Summary
| Expression | Definition |
|------------|------------|
| $M=\{O_1, \text{...} ,O_n\}$ | Mission |
| $O=⟨w,p,R⟩$ | Objective |
| $w$ | Relative objective weight |
| $p$ | Primary geophisical parameter/data product |
| $R=\{MR_1,...,MR_n\}$ | Objective Requirements |
| $MR=⟨At,Th,Sc⟩$ | Measurement Requirement | 
| $At$ | Attribute of the data product (e.g., horizontal spatial resolution) |
| $Th$ | Requirement satisfaction threshold values |
| $Sc$ | Requirement satisfaction score values |
| $x$ | Performance attribute |
| $u(x)$ | Preference function (maps performance attribute $x$ to requirement satisfaction value $u$) | 
| $E =⟨eventType, loc, t_{detect}, [d_{exp},S]⟩$ | Event |
| $t_{detect}$ | Event detection time |
| $d_{exp}$ | Expected event duration |
| $S$ | Event severity |
| $T=⟨param, loc, time, S, O⟩$ | Event-driven task |
| $i$ | Index for satellite $i$ |
| $j$ | Index for task $j$ |
| $k$ | Index for objective $k$ | 
| $l$ | Index for performance attribute $l$ |
| $Rel_{jk}$ | Relevance of task $j$ to objective $k$ |
| $P_{ijk}$ | Performance of an observation by agent $i$ of task $k$ on objective $k$ |
| $V_{ij}$ | Value of agent $i$ performing task $j$ |
| $U_{ij}$ | Utility of agent $i$ performing task $j$ |
| $E_{ij}$ | Cost of agent $i$ for performing task $j$ | 
| $\alpha$ | Cost normilizing parameter | 